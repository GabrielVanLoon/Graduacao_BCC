{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d7597f",
   "metadata": {},
   "source": [
    "# Exercício Aula 07 - Gerando Redes c/ Modelo BA e Configuration\n",
    "\n",
    "Author: Gabriel Van Loon\n",
    "\n",
    "Prof.:  Francisco Aparecido Rodrigues\n",
    "\n",
    "Universidade de São Paulo, São Carlos, Brasil.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaafe63",
   "metadata": {},
   "source": [
    "## Definindo as Funções e Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95066816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from networkx.algorithms import community, centrality\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from community import community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8fe81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution(GER):\n",
    "    vk = dict(GER.degree())\n",
    "    vk = list(vk.values()) # we get only the degree values\n",
    "    maxk = np.max(vk)\n",
    "    mink = np.min(min)\n",
    "    kvalues= np.arange(0,maxk+1) # possible values of k\n",
    "    Pk = np.zeros(maxk+1) # P(k)\n",
    "    for k in vk:\n",
    "        Pk[k] = Pk[k] + 1\n",
    "    Pk = Pk/sum(Pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    return kvalues,Pk\n",
    "\n",
    "def momment_of_degree_distribution(G,m):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    M = sum((k**m)*Pk)\n",
    "    return M\n",
    "\n",
    "def shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*np.math.log(p, 2)\n",
    "    return H\n",
    "\n",
    "\n",
    "def modularity(G, c):\n",
    "    \"\"\"\n",
    "    Calcula a modularidade da partição realizada na rede G nas c\n",
    "    comunidades. Outra opção é utilizar a função do networkx\n",
    "    networkx.algorithms.community.quality.modularity(G,c)\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    N = len(G)\n",
    "    M = G.number_of_edges()\n",
    "    Q = 0\n",
    "    for i in np.arange(0,N):\n",
    "        ki = len(list(G.neighbors(i)))\n",
    "        for j in np.arange(0,N):\n",
    "            if(c[i]==c[j]):\n",
    "                kj = len(list(G.neighbors(j)))\n",
    "                Q = Q + A[i,j]-(ki*kj)/(2*M)\n",
    "    Q = Q/(2*M)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3f615",
   "metadata": {},
   "source": [
    "## 1) Calcule a média do coeficiente de aglomeração e segundo momento do grau para uma rede BA com grau medio igual a 10 e n=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7f492ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "av_degree = 8\n",
    "m = int(av_degree/2)\n",
    "G = nx.barabasi_albert_graph(N, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d41beac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average clustering: 0.03434954127818049\n",
      "Second Moment 135.94400000000002\n",
      "Average Degree: 7.968\n"
     ]
    }
   ],
   "source": [
    "avg_deg = 2*G.number_of_edges()/N\n",
    "moment  = momment_of_degree_distribution(G,2)\n",
    "clustering = nx.average_clustering(G)\n",
    "\n",
    "print(\"Average clustering:\", clustering)\n",
    "print(\"Second Moment\", moment)\n",
    "print(\"Average Degree:\", avg_deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5215c",
   "metadata": {},
   "source": [
    "## 2) Considere uma rede aleatória (Erdos-Renyi) e uma BA com N=1000 vértices e grau médio 10. Qual o valor da entropia de Shannon da distrbuição do grau para essas redes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "562d8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, p = (1000, 0.01) # <k> = 10\n",
    "GER = nx.gnp_random_graph(N, p, seed=None, directed=False)\n",
    "\n",
    "N = 1000\n",
    "av_degree = 10\n",
    "m = int(av_degree/2)\n",
    "GBA = nx.barabasi_albert_graph(N, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8de795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon Entropy ER =  3.6741\n",
      "Shannon Entropy BA =  3.5949\n"
     ]
    }
   ],
   "source": [
    "print(\"Shannon Entropy ER = \", \"%3.4f\"%shannon_entropy(GER))\n",
    "print(\"Shannon Entropy BA = \", \"%3.4f\"%shannon_entropy(GBA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd359d",
   "metadata": {},
   "source": [
    "## 3) Considere o modelo de Barabarsi-Albert om N=1000 e grau médio igual a 10. Calcule o coeficiente de correlação de Pearson (rho) entre o grau e a medida eigenvector centrality. O que esse valor indica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb9f1edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.9400\n"
     ]
    }
   ],
   "source": [
    "eigen_centrality    = dict(nx.eigenvector_centrality(GBA))\n",
    "degree_centrality = dict(nx.degree_centrality(GBA))\n",
    "\n",
    "pearson_corr, _ = pearsonr(list(eigen_centrality.values()), list(degree_centrality.values()))\n",
    "\n",
    "print(\"Pearson Correlation:\", \"%3.4f\"%pearson_corr)]\n",
    "# Re: 0,9 indica que os hubs são os mais visitados em uma caminha aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ad25b",
   "metadata": {},
   "source": [
    "## 4) Calcule a correlação entre a medida de betweeness centrality e o grau para uma rede BA. Considerada N=500 e grau médio 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "288edfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "av_degree = 10\n",
    "m = int(av_degree/2)\n",
    "GBA = nx.barabasi_albert_graph(N, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "daa62af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.9674\n"
     ]
    }
   ],
   "source": [
    "bet_centrality    = dict(nx.betweenness_centrality(GBA))\n",
    "degree_centrality = dict(nx.degree_centrality(GBA))\n",
    "\n",
    "pearson_corr, _ = pearsonr(list(bet_centrality.values()), list(degree_centrality.values()))\n",
    "\n",
    "print(\"Pearson Correlation:\", \"%3.4f\"%pearson_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8d40c",
   "metadata": {},
   "source": [
    "## 5) Calcule o segundo momento do grau para o modelo de configuração com a=3 (coef da lei de potência (Zipf)). Considere N=500 e o valor mais próximo, pois os valores podem variar de uma simulação para outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4a8358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro precisamos montar a distribuição que queremos modelar \n",
    "N = 500\n",
    "a = 3.0\n",
    "seq = np.random.zipf(a, N) # Zipf distribution\n",
    "\n",
    "# Error preventing\n",
    "if(sum(seq)%2 != 0): # the sum of stubs have to be even\n",
    "    pos = np.random.randint(0, len(seq))\n",
    "    seq[pos] = seq[pos]+ 1\n",
    "\n",
    "# Passamos a configuração para o modelo :P\n",
    "GCM=nx.configuration_model(seq)\n",
    "\n",
    "# Pegando o maior componente\n",
    "Gcc = sorted(nx.connected_components(GCM), key=len, reverse=True)\n",
    "GCM = GCM.subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c2953bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Moment 14.916030534351144\n"
     ]
    }
   ],
   "source": [
    "print(\"Second Moment\", momment_of_degree_distribution(GCM,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f5727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
